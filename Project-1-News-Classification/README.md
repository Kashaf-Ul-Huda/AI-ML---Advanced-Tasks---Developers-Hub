# ğŸ“° News Topic Classifier using DistilBERT

## ğŸ“ Objective
Build and fine-tune a transformer model (DistilBERT) to classify **AG News headlines** into four categories:  
- **World** ğŸŒ  
- **Sports** ğŸ…  
- **Business** ğŸ’¼  
- **Sci/Tech** ğŸ”¬  

The model is deployed using **Gradio** for interactive inference.

---

## ğŸ“Š Dataset
- **AG News Dataset** (from Hugging Face `datasets`)  
- ~120K training samples, 7.6K test samples  
- Each sample: `Title`, `Description`, `Class Index`

---

## âš™ï¸ Methodology
1. **Preprocessing**
   - Combine Title + Description  
   - Map labels (`Class Index â†’ 0-3`)  
   - Tokenize with `DistilBertTokenizerFast`  

2. **Model Training**
   - Pretrained: `distilbert-base-uncased`  
   - Fine-tuned using Hugging Face **Trainer API**  
   - Optimizer: AdamW with LR=2e-5  
   - Metrics: Accuracy, Precision, Recall, F1  

3. **Evaluation**
   - Macro F1 & Accuracy on test split  
   - Example predictions tested with Gradio UI  

4. **Deployment**
   - Gradio interface for real-time text classification  

---

## âœ… Results
- **Accuracy:** ~85â€“90% (subset training)  
- **Macro F1:** ~0.85  
- Model performs well across all 4 categories.

---
